{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f776180b-b6e5-437e-98fd-fcbda1aed8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d63acf8-234a-416f-b157-38e703a0c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from src.data.make_dataset import TextDetoxificationDataset, bleu_score\n",
    "from src.models.train_model import BaselineTranslationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8df7bd71-336e-444f-b6b0-9a8e4fd2fbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 17 21:25:54 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 536.67                 Driver Version: 536.67       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A    0C    P3              11W /  30W |      0MiB /  4096MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c679cd-05ba-42c2-81df-0ac5ecaf7c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mirak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae008b8a7874b489b1d19d01b8294fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building vocab:   0%|          | 0/462221 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mirak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TextDetoxificationDataset(mode='train')\n",
    "val_dataset = TextDetoxificationDataset(mode='val', vocab=train_dataset.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0331ce7-3c41-48bd-8464-2228bd79a7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792d7ab861b841e9b0b05405b60c2751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Initializing with pretrained embeddings:   0%|          | 0/21707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirak\\PycharmProjects\\TextDetoxification\\src\\models\\train_model.py:43: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
      "  self.embeddings.weight.data[self.token2idx[word]] = torch.Tensor(glove_model.get_vector(word))\n"
     ]
    }
   ],
   "source": [
    "model = BaselineTranslationModel(token2idx=train_dataset.token2idx, emb_dim=200, hidden_dim=200, n_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed81e7b8-6d3e-49e3-afc5-62ec14365cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65601796 0.19445348\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    w1 = model.embeddings(torch.Tensor([model.token2idx['king']]).long()).numpy().squeeze()\n",
    "    w2 = model.embeddings(torch.Tensor([model.token2idx['queen']]).long()).numpy().squeeze()\n",
    "    w3 = model.embeddings(torch.Tensor([model.token2idx['man']]).long()).numpy().squeeze()\n",
    "    w4 = model.embeddings(torch.Tensor([model.token2idx['woman']]).long()).numpy().squeeze()\n",
    "    w5 = model.embeddings(torch.Tensor([model.token2idx['carrot']]).long()).numpy().squeeze()\n",
    "royal = w1 - w3\n",
    "s1 = (royal + w4).T @ w2 / np.linalg.norm(royal + w4) / np.linalg.norm(w2)\n",
    "s2 = (royal + w4).T @ w5 / np.linalg.norm(royal + w4) / np.linalg.norm(w5)\n",
    "print(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "632a3356-e0ed-4de3-b065-39edbf9eec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, inp, out, **inference_params):\n",
    "    mask = out != model.token2idx['<pad>'] # [batch_size, out_len]\n",
    "    targets_1hot = F.one_hot(out, len(model.out_voc)).to(torch.float32)\n",
    "\n",
    "    # outputs of the model, [batch_size, out_len, num_tokens]\n",
    "    logits_seq = model(inp, out, **inference_params)\n",
    "\n",
    "    # log-probabilities of all tokens at all steps, [batch_size, out_len, num_tokens]\n",
    "    logprobs_seq = torch.log(F.softmax(logits_seq, dim=-1))\n",
    "\n",
    "    # log-probabilities of correct outputs, [batch_size, out_len]\n",
    "    logp_out = (logprobs_seq * targets_1hot).sum(dim=-1)\n",
    "\n",
    "    # average cross-entropy over non-padding tokens\n",
    "    return - torch.masked_select(logp_out, mask).mean() # average loss, scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2635490-a6cc-45ad-8707-739513941965",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "loss_fn = compute_loss\n",
    "num_steps = 15000\n",
    "batch_size = 16\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_steps)\\\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aa1a89-7aa8-42cf-adf7-bb9795588850",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f973df-5d2e-4f54-8420-31a416426a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in tqdm(range(num_steps)):\n",
    "    step = len(metrics['train_loss']) + 1\n",
    "    batch_ix = np.random.randint(len(train_inp), size=batch_size)\n",
    "    batch_inp = train_dataset.vocab.to_matrix(train_inp[batch_ix]).to(device)\n",
    "    batch_out = train_dataset.vocab.to_matrix(train_out[batch_ix]).to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss_fn = compute_loss(model, batch_inp, batch_out)\n",
    "    loss_fn.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    metrics['train_loss'].append((step, loss_t.item()))\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        metrics['dev_bleu'].append((step, bleu_score(model, dev_inp, dev_out)))\n",
    "\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(12,4))\n",
    "        for i, (name, history) in enumerate(sorted(metrics.items())):\n",
    "            plt.subplot(1, len(metrics), i + 1)\n",
    "            plt.title(name)\n",
    "            plt.plot(*zip(*history))\n",
    "            plt.grid()\n",
    "        plt.show()\n",
    "        print(\"Mean loss=%.3f\" % np.mean(metrics['train_loss'][-10:], axis=0)[1], flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08ccb6e-4529-4138-9b57-81cc5d112cf8",
   "metadata": {},
   "source": [
    "### Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d59b591-6204-4070-ad7e-30c9dea75c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
